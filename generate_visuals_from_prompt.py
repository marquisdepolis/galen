"""
Generate the sql query from the user prompt for redshift tables
"""
import os
import json
import time
import re
import subprocess
import pandas as pd
from openai import OpenAI
from psycopg2.errors import UndefinedColumn
from db_connection import connect_sqlite
from utils.retry import retry_except
from tenacity import retry, stop_after_attempt, wait_fixed

def read_json(file_path):
    """
    Read json file
    """
    with open(file_path, 'r',encoding='utf-8') as file:
        json_data = json.load(file)
    return json_data

def get_schema_and_table_list(folder_path):
    """
    Get the schema for all the tables and the table list
    """
    schema_file_path = os.path.join(folder_path,f'combined_schema.json')

    all_schema = read_json(schema_file_path)

    tables_list = []
    for row in all_schema:
        for key in row:
            tables_list.append(key)

    return all_schema, tables_list

def is_sql_valid(sql: str) -> bool:
    """
    Basic validation to check for presence of a minimal expected SQL keyword
    """
    valid_keywords = {'SELECT', 'INSERT', 'UPDATE', 'DELETE'}
    return any(keyword in sql.upper() for keyword in valid_keywords)

def submit_message_and_create_run(client, assistant_id, prompt):
    """
    Submit the message and create the run
    """
    thread = client.beta.threads.create() # If you replace this globally it appends all answers to the one before.
    client.beta.threads.messages.create(thread_id=thread.id, role="user", content=prompt)
    return client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id, temperature=0.6), thread

def wait_on_run_and_get_response(client, run, thread):
    """
    Wait on run
    """
    while run.status in ("queued","in_progress"):
        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
        time.sleep(0.5)
    messages = client.beta.threads.messages.list(thread_id=thread.id, order="asc")
    return [m.content[0].text.value for m in messages if m.role == 'assistant']

def show_json(obj):
    """
    print the json response
    """
    print(json.loads(obj.model_dump_json()))

def extract_sql_query(raw_response):
    """
    Extracting the sql query from the response generated by gpt
    """
    # Remove initial and trailing special characters and any non-SQL syntax like markdown or SQL indicators
    query = raw_response.strip().strip("'''").strip().strip("```")
    # Remove any "sql" language label that might appear at the start of the query
    query = re.sub(r'^\s*sql\s*', '', query, flags=re.IGNORECASE)
    # Explicitly remove only leading and trailing square brackets or similar unwanted characters
    query = re.sub(r'^\[|\]$', '', query)
    # Ensure no unintentional character removal happens beyond what is specified
    return query

def create_output_df(prompts, responses, validity, latencies, model_name):
    """
    Get the output in dataframe format
    """
    new_rows = []
    for question, response, latency, validity in zip(prompts, responses, latencies, validity):
        new_rows.append({'Model': model_name, 'Question': question, 'Response': response, 'Latency': latency, 'Valid': validity})
    new_data = pd.DataFrame(new_rows)
    return new_data
    # new_data.to_csv(interim_csv_path, index=False)

def get_the_response_from_gpt(openai_client, schema, table_list, prompts, instrucions_to_model, model_name):
    """
    Send the user request and get the response
    """
    prompt_to_send = f"""Please write a SQLITE SQL query using this schema {schema} and table info {table_list} to answer the following question.
    The relevant DATABASES are attached as e.g.,: "ATTACH DATABASE 'db/ProteinNetwork.db' AS ProteinNetwork
    and ATTACH DATABASE 'db/DepMap.db' AS DepMap" and includes DepMap and ProteinNetwork.
    You have to write a SQLITE SQL query, ensure the format and syntax are perfect. Stick to SQLite-specific SQL syntax; avoid database prefixes unless using attached databases, and ensure you have ';' at the end, etc.
    DO NOT INCLUDE the names of Databases like ProteinNetwork.xxx, instead just use xxx, for the primary database.
    The tables in the databases are related to each other. While generating query, if COLUMN is in ANOTHER TABLE, please perform JOINS ONLY IF NECESSARY and then provide the query.
    If percent is asked, calulate the values in PERCENTAGE. 
    The SQLITE SQL query should be returned within ''' [SQL] '''.:\n\n{prompts}. 
    The query should be perfect and complete and will be run immediately on return, so be comprehensive and precise."""

    assistant = openai_client.beta.assistants.create(
    name="Galen Evaluator to read DB",
    instructions=instrucions_to_model,
    model=model_name
    )

    ASSISTANT_ID = assistant.id

    responses = []
    latencies = []
    valid = []

    start_time = time.time()  # Capture start time
    run, thread = submit_message_and_create_run(openai_client, ASSISTANT_ID, prompt_to_send)
    returned_response = wait_on_run_and_get_response(openai_client, run, thread)

    if isinstance(returned_response, list):
        returned_response = ' '.join(map(str, returned_response))

    returned_response = returned_response.replace("\\\\n", "\\n")
    returned_response = returned_response.strip()

    # print(f"The raw response is: {response}")
    extracted_sql = extract_sql_query(returned_response) # Get only the SQL query
    validity = is_sql_valid(returned_response) # Check if the SQL query is valid

    responses.append(extracted_sql)
    valid.append(validity)

    response = {
        "response": extracted_sql,
        "is_valid": valid
    }

    # print(f"The prompt is: {prompt}")
    # print(f"The response is: {response}")

    end_time = time.time()  # Capture end time
    latency = end_time - start_time  # Calculate latency
    latencies.append(latency)  # Store latency

    return prompts, responses, valid, latencies

def generate_df_for_visualization(openai_client, schema, table_list, prompts, instrucions_to_model, model_name):
    """
    Generate the dataframe from the query response
    """

    prompts, responses, valid, latencies = get_the_response_from_gpt(openai_client, schema, table_list, prompts, instrucions_to_model, model_name)
    output_df = create_output_df(prompts, responses, valid, latencies, model_name)
    
    query_response = output_df['Response'][0]
    query_response = query_response.replace('\n',' ')

    return query_response

def log_query_results(user_prompts,query_result,folder_path,try_value):
    """
    logs the queries returned from gpt to the csv file
    """
    log_filename = os.path.join(folder_path,'query_logs_v1.csv')
    query_log_df = pd.DataFrame(columns=['user_prompt','query_returned','try'])

    query_log_df.at[0,'user_prompt'] = ", ".join(user_prompts)
    query_log_df.at[0,'query_returned'] = query_result
    query_log_df.at[0,'try'] = try_value

    query_log_df.to_csv(log_filename,index=False,mode='a',header = (not os.path.exists(log_filename)))

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
@retry_except(exceptions_to_catch=(IndexError, ZeroDivisionError), tries=3, delay=2)
def validate_the_query(openai_client, schema, table_list, prompts, instrucions_to_model, model_name, folder_path):
    """
    Validate the query returned and if its incorrect then resolve it
    """

    try:
        query_response = generate_df_for_visualization(openai_client, schema, table_list, prompts, instrucions_to_model, model_name)
        log_query_results(prompts,query_response,folder_path,'first try')

        conn, cursor = connect_sqlite()
        cursor.execute(query_response)
        # Fetch all rows
        rows_fetched = cursor.fetchall()
        column_names = [desc[0] for desc in cursor.description]
        result_df = pd.DataFrame(rows_fetched,columns=column_names)
        return result_df
        
        cursor.close()

    except SyntaxError:
        prompts = [prompt_row + '. Query generated has incorrect SYNTAX. Please REVIEW and CORRECT the SYNTAX' for prompt_row in prompts]
        query_response = generate_df_for_visualization(openai_client, schema, table_list, prompts, instrucions_to_model, model_name)
        
        log_query_results(prompts,query_response,folder_path,'Syntax error')

        conn, cursor = connect_sqlite()
        cursor.execute(query_response)
        # Fetch all rows
        rows_fetched = cursor.fetchall()
        column_names = [desc[0] for desc in cursor.description]
        result_df = pd.DataFrame(rows_fetched,columns=column_names)
        return result_df
    
        cursor.close()

    except UndefinedColumn:
        prompts = [prompt_row + '. Query generated has incorrect column name. Please REVIEW and USE THE CORRECT COLUMNS present within the TABLES mentioned in SCHEMA' for prompt_row in prompts]
        query_response = generate_df_for_visualization(openai_client, schema, table_list, prompts, instrucions_to_model, model_name)
        
        log_query_results(prompts, query_response, folder_path, 'column error')

        conn, cursor = connect_sqlite()
        cursor.execute(query_response)
        # Fetch all rows
        rows_fetched = cursor.fetchall()
        column_names = [desc[0] for desc in cursor.description]
        result_df = pd.DataFrame(rows_fetched,columns=column_names)
        return result_df
    
        cursor.close()
    
    except:
        print("Please try again")


@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
@retry_except(exceptions_to_catch=(IndexError, ZeroDivisionError), tries=3, delay=2)
def generate_visual_from_df(openai_client, prompt, visual_prompt, instruction, model_name, result_df):
    """
    Generate the visualization from the dataframe
    """
    visual_assistant = openai_client.beta.assistants.create(
        name="Visual Builder",
        instructions=instruction,
        model=model_name,
    )

    VIUSAL_ASSISTANT_ID = visual_assistant.id

    visual_prompts = list(f"{prompt[0]} using {visual_prompt}.")
    print(prompt)
    visual_prompt = f"""Given the dataframe build the VISUALS using seaborn and it should be displayed on streamlit. 
    Always add a legend with various colors where appropriate. Always display data values. 
    The visualization code MUST only use data fields that exist in the dataframe {result_df}. 
    ALWAYS USE DATAFRAME VARIABLE AS result_df. You MUST return a FULL PYTHON PROGRAM ENCLOSED IN BACKTICKS ``` that starts with an import statement. import all necessary libraries. 
    DO NOT add any explanation. \n\n{visual_prompts}"""

    run, thread = submit_message_and_create_run(openai_client, VIUSAL_ASSISTANT_ID, visual_prompt)
    response = wait_on_run_and_get_response(openai_client, run, thread)
    if isinstance(response, list):
        response = ' '.join(map(str, response))
    response = response.replace("\\\\n", "\\n")
    response = response.strip()
    final_response = response.split('```python')[-1].split('```')[0]

    exec(final_response)

if __name__ == '__main__':
    user_prompt = []
    dirname = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(dirname,'config')
    log_path = os.path.join(dirname,'logs')
    
    subprocess.run(['python3', 'get_table_schema.py'])
    final_schema, tables = get_schema_and_table_list(config_path)
    info = read_json(os.path.join(config_path,'info.json'))

    INSTRUCTION = info.get('DB_instructions')
    OBJECTIVE = info.get('objective')
    GPT_MODEL = info.get('GPT_4')
    # CLAUDE = info.get('CLAUDE')
    # OLLAMA = info.get('OLLAMA')
    VISUAL_INSTRUCTIONS = info.get('Visual_Builder')

    openai_client_session = OpenAI(api_key=os.getenv('OPEN_AI_API_KEY'))

    user_prompt_input = input("Please enter your query: \n")
    visual_prompt = input("Please mention the type of graph to visualize: ")
    user_prompt.append(user_prompt_input)

    df_returned = validate_the_query(openai_client_session, final_schema, tables, user_prompt,
                                                INSTRUCTION, GPT_MODEL, log_path)

    generate_visual_from_df(openai_client_session, user_prompt, visual_prompt, VISUAL_INSTRUCTIONS, GPT_MODEL, df_returned)
