{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (699531674.py, line 108)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 108\u001b[0;36m\u001b[0m\n\u001b[0;31m    'Latency': latency,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# GPT-4 dynamic evaluation\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from config import config\n",
    "import openai\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "import random\n",
    "\n",
    "INSTRUCTION = config.INSTRUCTION\n",
    "F_NAME = config.F_NAME\n",
    "config.set_mode(\"dynamic\")\n",
    "\n",
    "folder_path = 'files'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "def load_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def get_random_perturbation(perturbations):\n",
    "    category = random.choice(list(perturbations.keys()))\n",
    "    perturbation = random.choice(list(perturbations[category].items()))\n",
    "    return category, perturbation\n",
    "\n",
    "perturbations = load_file(config.perturbations)\n",
    "knowledgebase = load_file(config.knowledgebase)\n",
    "\n",
    "client = OpenAI()\n",
    "def show_json(obj):\n",
    "    print(json.loads(obj.model_dump_json()))\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=f\"{F_NAME} AI Dynamic Evaluator\",\n",
    "    instructions=config.INSTRUCTION,\n",
    "    model=config.GPT_MODEL,\n",
    ")\n",
    "show_json(assistant)\n",
    "\n",
    "# Utility functions\n",
    "def read_csv(file_path):\n",
    "    return pd.read_excel(file_path)\n",
    "\n",
    "def process_data_for_gpt(data):\n",
    "    prompts = []\n",
    "    for _, row in data.iterrows():\n",
    "        question = row['Question']\n",
    "        prompt = f\"Please try your best to answer the following question.:\\n\\n{question}\"\n",
    "        prompts.append(prompt)\n",
    "    return prompts\n",
    "\n",
    "def submit_message_and_create_run(assistant_id, prompt):\n",
    "    thread = client.beta.threads.create() # If you replace this globally it appends all answers to the one before.\n",
    "    client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=prompt)\n",
    "    return client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id), thread\n",
    "\n",
    "def wait_on_run_and_get_response(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        time.sleep(0.5)\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")\n",
    "    return [m.content[0].text.value for m in messages if m.role == 'assistant']\n",
    "\n",
    "def ask_gpt4(prompt, ASSISTANT_ID):\n",
    "    run, thread = submit_message_and_create_run(ASSISTANT_ID, prompt)\n",
    "    response = wait_on_run_and_get_response(run, thread)\n",
    "    if isinstance(response, list):\n",
    "        response = ' '.join(map(str, response))\n",
    "    response = response.replace(\"\\\\\\\\n\", \"\\\\n\")\n",
    "    response = response.strip()\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "def process_question_with_gpt4(row, assistant_id):\n",
    "    start_time = time.time()  # Capture start time\n",
    "    original_question = row['Question']\n",
    "    category = row.get('Category', 'Static')  # Default to 'Static' if not present\n",
    "    if category != \"Dynamic\":\n",
    "        # Dynamic question processing logic\n",
    "        first_response = ask_gpt4(original_question, assistant_id)\n",
    "        category, (perturbation, description) = get_random_perturbation(perturbations)\n",
    "        perturbed_qn = f\"{original_question}\\nResponse: {first_response}\\nChange in circumstances: {perturbation} - {description}\\n What should change in the response?\"\n",
    "        perturbed_response = ask_gpt4(perturbed_qn, assistant_id)\n",
    "        final_analysis_qn = f\"Original Question: {original_question}\\nOrig Response: {first_response} \\nPerturbation ({category}): {perturbation} - {description}\\n {perturbed_response}\\nKnowledgebase Content: {knowledgebase}\\n Now consider the knowlegebase, what else ought we to do?\"\n",
    "        final_analysis_response = ask_gpt4(final_analysis_qn, assistant_id)\n",
    "    else:\n",
    "        # Static question processing logic\n",
    "        first_response = ask_gpt4(original_question, assistant_id)\n",
    "        perturbed_qn = perturbed_response = final_analysis_qn = final_analysis_response = \"n/a\"\n",
    "\n",
    "    end_time = time.time()  # Capture end time\n",
    "    latency = (end_time - start_time)/3  # Calculate latency\n",
    "\n",
    "    return {\n",
    "        'Model': config.GPT_MODEL,\n",
    "        'Question': original_question, \n",
    "        'Response': first_response, \n",
    "        'Perturbed Question': perturbed_qn, \n",
    "        'Perturbed Response': perturbed_response, \n",
    "        'Final Analysis Question': final_analysis_qn, \n",
    "        'Final Analysis Response': final_analysis_response,\n",
    "        'Latency': latency,\n",
    "        'Category': row['Category'],\n",
    "        'Type': row['Type']\n",
    "    }\n",
    "\n",
    "# Modify DataFrame to include new columns\n",
    "new_data_columns = ['Model', 'Question', 'Response', 'Perturbed Question', 'Perturbed Response', 'Final Analysis Question', 'Final Analysis Response', 'Latency', 'Category', 'Type']\n",
    "results_df = pd.DataFrame(columns=new_data_columns)\n",
    "data = read_csv(config.questions)\n",
    "prompts = process_data_for_gpt(data)\n",
    "ASSISTANT_ID = assistant.id\n",
    "\n",
    "# Process each question\n",
    "for index, row in data.iterrows():\n",
    "    processed_info = process_question_with_gpt4(row, ASSISTANT_ID)\n",
    "    results_df = results_df.append(processed_info, ignore_index=True)\n",
    "\n",
    "# Save the results\n",
    "results_df.to_excel(config.gpt4results_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bl/nkj7dq8s6m16hf4zmr47vkfr0000gn/T/ipykernel_8599/3567630668.py:37: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  contains_mask = big_df[big_col].str.contains(row[small_col])\n"
     ]
    }
   ],
   "source": [
    "# How to combine files together into one\n",
    "import re\n",
    "import config\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "from config import config, reset_config\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "import json\n",
    "\n",
    "INSTRUCTION = config.INSTRUCTION\n",
    "F_NAME = config.F_NAME\n",
    "config.set_mode(\"dynamic\")\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove non-ASCII characters from the text.\n",
    "    \"\"\"\n",
    "    return ''.join(char for char in text if char.isascii())\n",
    "\n",
    "def create_combined_csv(original_csv_path, interim_csv_path, combined_csv_path):\n",
    "    # Read the original and interim data\n",
    "    original_data = pd.read_excel(original_csv_path) #, encoding='utf-8-sig'\n",
    "    interim_data = pd.read_excel(interim_csv_path)\n",
    "\n",
    "    # Combine the data\n",
    "    combined_data = pd.concat([original_data, interim_data], ignore_index=True)\n",
    "\n",
    "    # Save the combined data to a new CSV file\n",
    "    combined_data.to_excel(combined_csv_path, index=False)\n",
    "\n",
    "def merge_on_contains(big_df, small_df, big_col, small_col):\n",
    "    # Lowercase and strip whitespace for more effective matching\n",
    "    big_df[big_col] = big_df[big_col].str.lower().str.strip()\n",
    "    small_df[small_col] = small_df[small_col].str.lower().str.strip()\n",
    "\n",
    "    # Check if 'category' column exists in small_df\n",
    "    if 'category' in small_df.columns:\n",
    "        # Create a new column for the merged category in big_df\n",
    "        big_df['category'] = ''\n",
    "\n",
    "        # Iterate over the small dataframe and update the category in the big dataframe\n",
    "        for _, row in small_df.iterrows():\n",
    "            contains_mask = big_df[big_col].str.contains(row[small_col])\n",
    "            big_df.loc[contains_mask, 'category'] = row['category']\n",
    "    else:\n",
    "        # Handle the case when 'category' column does not exist\n",
    "        # For example, you can set a default category or leave it as it is\n",
    "        big_df['category'] = 'default_category'  # or any other handling logic\n",
    "\n",
    "    return big_df\n",
    "\n",
    "create_combined_csv(config.llmresults_file_path, config.gpt4results_csv_path, config.results_file_path)\n",
    "\n",
    "# Reading the files\n",
    "questions_df = pd.read_excel(config.questions)\n",
    "results_df = pd.read_excel(config.results_file_path)\n",
    "\n",
    "# Ensure the total number of questions in results_grouped_by_model.xlsx is a multiple of the number in questions.xlsx\n",
    "if len(results_df) % len(questions_df) != 0:\n",
    "    print(len(results_df))\n",
    "    print(len(questions_df))\n",
    "    raise ValueError(\"The total number of questions in results_grouped_by_model.xlsx must be a multiple of the number in questions.xlsx.\")\n",
    "\n",
    "# Replace questions in results_grouped_df with those from questions_df\n",
    "num_repetitions = len(results_df) // len(questions_df)\n",
    "repeated_questions = pd.concat([questions_df['Question']] * num_repetitions, ignore_index=True)\n",
    "results_df['Question'] = repeated_questions\n",
    "\n",
    "# All info saved in one results file! \n",
    "# Save the modified DataFrame to a new Excel file\n",
    "results_df.to_excel(config.results_file_path, index=False)  # Replace with your desired path\n",
    "\n",
    "# Applying the merge_on_contains function\n",
    "merged_df = merge_on_contains(results_df, questions_df, 'Question', 'Question')\n",
    "\n",
    "# Sorting the DataFrame by the 'Question' column\n",
    "sorted_df = results_df.sort_values(by=['Question'])\n",
    "\n",
    "combined_df = sorted_df.fillna('')\n",
    "# Save the combined data\n",
    "combined_df.to_excel(config.combined_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archive the intermediate files\n",
    "import os\n",
    "import glob\n",
    "from config import config\n",
    "directory = 'files/'\n",
    "archive_directory = os.path.join(directory, '#Archive')\n",
    "\n",
    "# Create the #Archive directory if it doesn't exist\n",
    "if not os.path.exists(archive_directory):\n",
    "    os.makedirs(archive_directory)\n",
    "\n",
    "# List all files that start with F_NAME and exclude the specified files\n",
    "files_to_move = [f for f in glob.glob(f\"{directory}/{config.F_NAME}_*\") \n",
    "                 if '_model_rankings' not in f and '_llmeval_results' not in f and 'questions' not in f and '_results_grouped_by_question_' not in f and '_allresults_grouped_by_model_' not in f]\n",
    "\n",
    "# Move the files to the #Archive folder\n",
    "for file in files_to_move:\n",
    "    os.rename(file, os.path.join(archive_directory, os.path.basename(file)))\n",
    "    print(f\"Moved file: {file} to {archive_directory}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
