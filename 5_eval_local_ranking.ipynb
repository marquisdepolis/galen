{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start ollama according to the script if you need to \n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from pydantic import BaseModel, ValidationError, conint\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "INSTRUCTION = config['instructions']\n",
    "F_NAME = config[\"name\"]\n",
    "\n",
    "class ModelRanking(BaseModel):\n",
    "    Name: str\n",
    "    Ranking: conint(ge=0)  # conint(ge=0) means a constrained integer greater than or equal to 0\n",
    "\n",
    "class ResponseModel(BaseModel):\n",
    "    Model: list[ModelRanking]\n",
    "\n",
    "template = {\n",
    " \"Model\": [\n",
    "  {\"Name\": \"mistral-7b\", \"Ranking\": \"\"},\n",
    "  {\"Name\": \"llama2-70b\", \"Ranking\": \"\"},\n",
    "  {\"Name\": \"qwen-14b\", \"Ranking\": \"\"},\n",
    "  {\"Name\": \"yi-34b\", \"Ranking\": \"\"},\n",
    "  {\"Name\": \"mixtral-instruct\", \"Ranking\": \"\"},\n",
    "  {\"Name\": \"falcon-40b\", \"Ranking\": \"\"},\n",
    "  {\"Name\": \"gpt-4-1106\", \"Ranking\": \"\"},\n",
    "  {\"Name\": \"deepseek_33bq\", \"Ranking\": \"\"}\n",
    " ]\n",
    "}\n",
    "model = \"llama2:7b\"\n",
    "def generate_text(data):\n",
    "    r = requests.post(\"http://localhost:11434/api/generate\", json=data, stream=False)\n",
    "    full_response = json.loads(r.text)\n",
    "    resp = json.loads(full_response[\"response\"])\n",
    "    # resp = (json.dumps(json.loads(full_response[\"response\"]), indent=2))\n",
    "    print(f\"/n/n Response is: /n {resp}\")\n",
    "    return resp\n",
    "\n",
    "def read_excel(filepath, column_name):\n",
    "    df = pd.read_excel(filepath)\n",
    "    return df[column_name].tolist()\n",
    "\n",
    "def validate_response(response):\n",
    "    try:\n",
    "        ResponseModel(**response)\n",
    "        return True\n",
    "    except ValidationError:\n",
    "        return False\n",
    "    \n",
    "def make_json(data):\n",
    "    response_full = []\n",
    "    for index, info in enumerate(data, start=1):  # Start indexing from 1\n",
    "        valid_response = False\n",
    "        attempts = 0\n",
    "        while not valid_response and attempts < 3:\n",
    "            print(f\"The data is: /n {info}\")\n",
    "            prompt = f\"Extract the model rankings from {info} and give me the response as a JSON. \\nUse the following template: {json.dumps(template)}.\"\n",
    "            print(\"/n/n We're starting! /n\")\n",
    "            response_data = {\n",
    "                \"model\": model,\n",
    "                \"prompt\": prompt,\n",
    "                \"format\": \"json\",\n",
    "                \"stream\": False,\n",
    "                \"options\": {\"temperature\": 0.1, \"top_p\": 0.99, \"top_k\": 100},\n",
    "            }\n",
    "            response = generate_text(response_data)\n",
    "            valid_response = validate_response(response)\n",
    "            attempts += 1\n",
    "        if valid_response:\n",
    "            response_full.append({\"index\": index, \"response\": response})\n",
    "        else:\n",
    "            print(\"Failed to get a valid response after 3 attempts.\")\n",
    "            response = ''.join([str(item) for item in response])\n",
    "            response_full.append({\"index\": index, \"response\": {\"Model\": []}})\n",
    "    return response_full\n",
    "\n",
    "def main():\n",
    "    filepath = f'files/{F_NAME}_llmeval_results.xlsx'\n",
    "    column = 'Evaluation of responses from GPT-4'\n",
    "    dataframe = read_excel(filepath, column)\n",
    "    json_output = make_json(dataframe)\n",
    "    with open(\"output.json\", \"w\") as f:\n",
    "        json.dump(json_output, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Read the JSON file\n",
    "with open(\"output.json\", \"r\") as f:\n",
    "    json_strings = json.load(f)\n",
    "\n",
    "unique_models = set()\n",
    "for item in json_strings:\n",
    "    response_obj = item[\"response\"]  # Directly use the response object\n",
    "    for model in response_obj[\"Model\"]:\n",
    "        unique_models.add(model['Name'])\n",
    "\n",
    "# Convert the set to a list and sort it\n",
    "unique_models = sorted(list(unique_models))\n",
    "\n",
    "data = []\n",
    "for item in json_strings:\n",
    "    row = {model: '' for model in unique_models}  # Initialize all model rankings as empty\n",
    "    row['ID'] = item['index']  # Use the index from the original data\n",
    "    for model in item[\"response\"][\"Model\"]:\n",
    "        row[model['Name']] = model.get('Ranking', '')\n",
    "    data.append(row)\n",
    "\n",
    "# Create DataFrame and write to Excel\n",
    "df = pd.DataFrame(data)\n",
    "excel_file = f'files/{F_NAME}_model_rankings.xlsx'\n",
    "df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f\"Data written to {excel_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
