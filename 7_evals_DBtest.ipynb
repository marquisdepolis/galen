{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from llama_index import SQLDatabase, ServiceContext\n",
    "import sqlite3\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.indices.struct_store.sql_query import (\n",
    "    SQLTableRetrieverQueryEngine,\n",
    ")\n",
    "from llama_index.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index import VectorStoreIndex\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    ")\n",
    "import os\n",
    "\n",
    "db_dir = \"files/db\"\n",
    "db_files = [os.path.join(db_dir, file) for file in os.listdir(db_dir) if file.endswith('.db')]\n",
    "\n",
    "for db_file in db_files:\n",
    "    engine = create_engine('sqlite:///' + db_file)\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get all tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "    tables = cursor.fetchall()\n",
    "    for table in tables:\n",
    "        print(table[0])\n",
    "\n",
    "    table_name = table[0]\n",
    "    print(f\"\\nTable: {table_name} in {db_file}\")\n",
    "    metadata_obj = MetaData()\n",
    "    print(metadata_obj)\n",
    "    # Get table schema\n",
    "    print(\"Schema:\")\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    schema = cursor.fetchall()\n",
    "    for column in schema:\n",
    "        print(column)\n",
    "\n",
    "    # Get the first five rows\n",
    "    # print(\"\\nFirst 5 rows:\")\n",
    "    cursor.execute(f\"SELECT * FROM {table_name} LIMIT 5;\")\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "\n",
    "    llm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\")\n",
    "    service_context = ServiceContext.from_defaults(llm=llm)\n",
    "    sql_database = SQLDatabase(engine)\n",
    "    # set Logging to DEBUG for more detailed outputs\n",
    "    table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "    table_schema_objs = [\n",
    "        (SQLTableSchema(table_name=str(table_name)))\n",
    "    ]  # add a SQLTableSchema for each table\n",
    "\n",
    "    obj_index = ObjectIndex.from_objects(\n",
    "        table_schema_objs,\n",
    "        table_node_mapping,\n",
    "        VectorStoreIndex,\n",
    "    )\n",
    "    query_engine = SQLTableRetrieverQueryEngine(\n",
    "        sql_database, obj_index.as_retriever(similarity_top_k=3)\n",
    "    )\n",
    "    response = query_engine.query(\"How many different proteins with lymphoid tissue?\")\n",
    "    display(Markdown(f\"<b>{response}</b>\"))\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined schema of tables\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, String\n",
    "import re\n",
    "def combine_schemas(db_files):\n",
    "    combined_schema = {}\n",
    "\n",
    "    for db_file in db_files:\n",
    "        engine = create_engine('sqlite:///' + db_file)\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Get all tables\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            metadata_obj = MetaData()\n",
    "            \n",
    "            # Get table schema\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "            schema = cursor.fetchall()\n",
    "\n",
    "            # Create a Table object to store schema info\n",
    "            table_obj = Table(table_name, metadata_obj)\n",
    "\n",
    "            for column in schema:\n",
    "                col_name, col_type = column[1], column[2]\n",
    "                # Add column to the table object\n",
    "                table_obj.append_column(Column(col_name, String))\n",
    "\n",
    "            # Serialize table schema\n",
    "            schema_info = [{\"column_name\": col.name, \"data_type\": str(col.type)} for col in table_obj.columns]\n",
    "            combined_schema[f\"{table_name} in {db_file}\"] = schema_info\n",
    "\n",
    "        conn.close()\n",
    "\n",
    "    return combined_schema\n",
    "\n",
    "def save_schema_to_json(combined_schema, filename=\"combined_schema.json\"):\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(combined_schema, file, indent=4)\n",
    "\n",
    "# Paths to your database files\n",
    "db_files = [\"files/db/CCLEGisticCNDB.db\" , 'files/db/CCLEMutDB.db', 'files/db/CCLEVarDB.db']\n",
    "all_schemas = combine_schemas(db_files)\n",
    "save_schema_to_json(all_schemas)\n",
    "\n",
    "# Now the schema is saved in 'combined_schema.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A check\n",
    "import re \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def extract_sql(llm_response: str) -> str:\n",
    "    # If the llm_response contains a markdown code block, with or without the sql tag, extract the sql from it\n",
    "    sql = re.search(r\"```sql\\n(.*)```\", llm_response, re.DOTALL)\n",
    "    if sql:\n",
    "        log(f\"Output from LLM: {llm_response} \\nExtracted SQL: {sql.group(1)}\")\n",
    "        return sql.group(1)\n",
    "\n",
    "    sql = re.search(r\"```(.*)```\", llm_response, re.DOTALL)\n",
    "    if sql:\n",
    "        log(f\"Output from LLM: {llm_response} \\nExtracted SQL: {sql.group(1)}\")\n",
    "        return sql.group(1)\n",
    "\n",
    "    return llm_response\n",
    "\n",
    "def is_sql_valid(sql: str) -> bool:\n",
    "    # This is a check to see the SQL is valid and should be run\n",
    "    # This simple function just checks if the SQL contains a SELECT statement\n",
    "\n",
    "    if \"SELECT\" in sql.upper():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found.\n",
      "You are an exceptional computational biologist and genomics expert and know everything about drug discovery.. Please write the appropriate SQL query using these three tables. The tables can be understood as utils/database_description.json. Try to answer the following question. The SQL should be returned within ''' SQL query '''. \"Which cell lines have high dependency for the target of interest for the gene POLR3E?\"\n",
      "Output is: <generator object Prediction.output_iterator at 0x177adec50>\n",
      "Output is: ``` SQL   -- Ass uming the following table names and column names based on the given context  -- Table: cell_ lines  -- Columns: id, name, gene_ depend ency_ sc ores  -- Table: targets  -- Columns: id, name, gene_ symbol  -- Table: gene_ target_ map  -- Columns: cell_ line_ id, target_ id, score   -- SQL query  SELECTc. name  FROM cell_ linesc  JO IN gene_ target_ mapg tm ONc. id=g tm. cell_ line_ id  JO IN targetst ONg tm. target_ id=t. id W HEREt.g ene_ symbol=' POLR3E'  ORDER BYg tm. score DESC;   -- This query will return the names of cell lines that have high dependency for the targetP OLR3E.  -- The result is ordered in desc ending order of dependency score.  ```\n",
      "You are an exceptional computational biologist and genomics expert and know everything about drug discovery.. Please write the appropriate SQL query using these three tables. The tables can be understood as utils/database_description.json. Try to answer the following question. The SQL should be returned within ''' SQL query '''. \"For the gene POLR3E, identify indications with significant differential expression in cancer vs normal tissue. Is it overexpressed or underexpressed in tumor tissue?\"\n",
      "Output is: <generator object Prediction.output_iterator at 0x177ade890>\n",
      "Output is: ``` sql SQL query    -- Ass uming the tables are named' gen es ',' express ions_c ancer ', and' express ions_ normal'  -- and they have the following columns: genes.g ene_ id, genes.g ene_ name, expressions_c ancer. sample_ type, expressions_c ancer. expression_ value, expressions_ normal. expression_ value   SELECTg.g ene_ name, CA SE   WH EN avg( ec. expression_ value)> avg( en. expression_ value) TH EN' Over ex pressed'   EL SE' Und erex pressed'   END as expression_ status  FROM genesg  JO IN expressions_c ancer ec ONg.g ene_ id= ec.g ene_ id  JO IN expressions_ normal en ONg.g ene_ id= en.g ene_ id W HEREg.g ene_ name=' POLR3E'  GROUP BYg.g ene_ name;  ```   This query will return the gene name and its expression status (' Over ex pressed' or' Und erex pressed ') based on the average expression values in cancer and normal tissue for the geneP OLR3E.\n",
      "You are an exceptional computational biologist and genomics expert and know everything about drug discovery.. Please write the appropriate SQL query using these three tables. The tables can be understood as utils/database_description.json. Try to answer the following question. The SQL should be returned within ''' SQL query '''. \"Are there specific regions of the protein of the gene POLR3E where mutations occur at a higher frequency?\"\n",
      "Output is: <generator object Prediction.output_iterator at 0x177a31f30>\n",
      "Output is: ``` sql   -- Ass uming the tables are named\" gen es \",\" prote ins \", and\" mut ations\"  -- and they have the following columns:  -- genes: id( int ), gene_ symbol( var char ), protein_ id( int)  -- prote ins: id( int ), protein_ id( int ), sequence( var char)  -- mut ations: id( int ), gene_ id( int ), position( int ), frequency( float)   -- This query calcul ates the mut ation frequency for each position in the protein sequence of geneP OLR3E  SELECTp. position AS position, AVG(m. frequency) AS avg_ frequency  FROM genesg  JO IN prote insp ONg. prote in_ id=p. id  JO IN mut ationsm ONg. id=m.g ene_ id W HEREg.g ene_ symbol=' POLR3E'  GROUP BYp. position   -- This query ident ifies positions witha mut ation frequency abovea certain threshold(e.g ., 0.05)  SET@ threshold= 0.05;   SELECTp. position AS position  FROM(   SE LECTp. position, AVG(m. frequency) AS avg_ frequency   FROM genesg   JO IN prote insp ONg. prote in_ id=p. id   JO IN mut ationsm ONg. id=m.g ene_ id   WHEREg.g ene_ symbol=' POLR3E'  G RO UP BYp. position )x W HERE avg_ frequency>@ threshold;   '''   -- This query comb ines the previous two queries into one to find specific regions of the protein where mut ations occur ata higher frequency for geneP OLR3E.\n",
      "Output is: ``` sql   -- Ass uming the tables are named\" gen es \",\" prote ins \", and\" mut ations\"  -- and they have the following columns:  -- genes: id( int ), gene_ symbol( var char ), protein_ id( int)  -- prote ins: id( int ), protein_ id( int ), sequence( var char)  -- mut ations: id( int ), gene_ id( int ), position( int ), frequency( float)   -- This query calcul ates the mut ation frequency for each position in the protein sequence of geneP OLR3E  SELECTp. position AS position, AVG(m. frequency) AS avg_ frequency  FROM genesg  JO IN prote insp ONg. prote in_ id=p. id  JO IN mut ationsm ONg. id=m.g ene_ id W HEREg.g ene_ symbol=' POLR3E'  GROUP BYp. position   -- This query ident ifies positions witha mut ation frequency abovea certain threshold(e.g ., 0.05)  SET@ threshold= 0.05;   SELECTp. position AS position  FROM(   SE LECTp. position, AVG(m. frequency) AS avg_ frequency   FROM genesg   JO IN prote insp ONg. prote in_ id=p. id   JO IN mut ationsm ONg. id=m.g ene_ id   WHEREg.g ene_ symbol=' POLR3E'  G RO UP BYp. position )x W HERE avg_ frequency>@ threshold;   '''   -- This query comb ines the previous two queries into one to find specific regions of the protein where mut ations occur ata higher frequency for geneP OLR3E.\n",
      "You are an exceptional computational biologist and genomics expert and know everything about drug discovery.. Please write the appropriate SQL query using these three tables. The tables can be understood as utils/database_description.json. Try to answer the following question. The SQL should be returned within ''' SQL query '''. \"For the gene POLR3E, determine how many of the mutations are pathogenic.\"\n",
      "Output is: <generator object Prediction.output_iterator at 0x177adec50>\n",
      "Output is: ``` sql   -- Ass uming the tables are named as\" gen es \",\" mut ations \", and\" vari ants\" with the following columns:  -- genes: id( int ), name( var char)  -- mut ations: id( int ), gene_ id( int ), is_ path ogen ic( boolean)  -- vari ants: id( int ), mut ation_ id( int ), gene_ id( int)   -- SQL query to determine the number of path ogen ic mut ations for geneP OLR3E  SELECT CO UNT( *)  FROM mut ationsm  JO IN genesg ONm.g ene_ id=g. id  JO IN vari antsv ONm. id=v. mut ation_ id W HEREg. name=' POLR3E' ANDm. is_ path ogen ic= true;  ```   This query performsa join between the\" gen es \",\" mut ations \", and\" vari ants\" tables, filter ing the results to only include rows where the gene name is\" POLR3E\" and the mut ation is path ogen ic. The result is the number of rows, which represents the number of path ogen ic mut ations for geneP OLR3E.\n",
      "You are an exceptional computational biologist and genomics expert and know everything about drug discovery.. Please write the appropriate SQL query using these three tables. The tables can be understood as utils/database_description.json. Try to answer the following question. The SQL should be returned within ''' SQL query '''. \"Which mutations in PAS domain for the target protein exhibit high selectivity for the prostate cancer cell lines?\"\n",
      "Output is: <generator object Prediction.output_iterator at 0x177a31f30>\n",
      "Output is: ``` SQL   -- Ass uming the following table names and columns based on the given context  -- Table: prote ins( id, name, pas_ domain_ sequence)  -- Table: mut ations( id, protein_ id, position, type)  -- Table: cell_ lines( id, name, ic50)   -- First, join prote ins and mut ations tables using protein_ id  SELECTp. name AS protein_ name,m. position,m. type  FROM prote insp  JO IN mut ationsm ONp. id=m. prote in_ id W HEREp. name=' target_ prote in' -- replace with the actual protein name  ANDp. pas_ domain_ sequence IS NOT NULL -- assuming pas_ domain_ sequence is stored in prote ins table   -- Then, filter mut ations that are located inP AS domain  -- This assumes that the length ofP AS domain is known and stored ina variable or hardc oded value  -- Re place' start_ index' and' end_ index' with actual values  -- For example, if theP AS domain of the target protein is between positions 100 and 200:  ANDm. positionB ET WE EN start_ index AND end_ index   -- Join the result with cell_ lines table using ic50 values  -- Ass uming the select ivity is in vers ely proport ional to ic50, so lower ic50 values indicate higher select ivity for pro state cancer cell lines  -- Re place' pro state_ cell_ line_ id' with the actual id of the pro state cell line  SELECT protein_ name, position, type, ic50  FROM(   SE LECTp. name AS protein_ name,m. position,m. type   FROM prote insp   JO IN mut ationsm ONp. id=m. prote in_ id   WHEREp. name=' target_ prote in'   ANDp. pas_ domain_ sequence IS NOT NULL   ANDm. positionB ET WE EN start_ index AND end_ index ) mut ations  JO IN cell_ lines cl ON mut ations. id= cl. mut ation_ id -- assuming there isa mut ation_ id column in cell_ lines table W HERE cl. id= pro state_ cell_ line_ id  ORDER BY\n",
      "Output is: ``` SQL   -- Ass uming the following table names and columns based on the given context  -- Table: prote ins( id, name, pas_ domain_ sequence)  -- Table: mut ations( id, protein_ id, position, type)  -- Table: cell_ lines( id, name, ic50)   -- First, join prote ins and mut ations tables using protein_ id  SELECTp. name AS protein_ name,m. position,m. type  FROM prote insp  JO IN mut ationsm ONp. id=m. prote in_ id W HEREp. name=' target_ prote in' -- replace with the actual protein name  ANDp. pas_ domain_ sequence IS NOT NULL -- assuming pas_ domain_ sequence is stored in prote ins table   -- Then, filter mut ations that are located inP AS domain  -- This assumes that the length ofP AS domain is known and stored ina variable or hardc oded value  -- Re place' start_ index' and' end_ index' with actual values  -- For example, if theP AS domain of the target protein is between positions 100 and 200:  ANDm. positionB ET WE EN start_ index AND end_ index   -- Join the result with cell_ lines table using ic50 values  -- Ass uming the select ivity is in vers ely proport ional to ic50, so lower ic50 values indicate higher select ivity for pro state cancer cell lines  -- Re place' pro state_ cell_ line_ id' with the actual id of the pro state cell line  SELECT protein_ name, position, type, ic50  FROM(   SE LECTp. name AS protein_ name,m. position,m. type   FROM prote insp   JO IN mut ationsm ONp. id=m. prote in_ id   WHEREp. name=' target_ prote in'   ANDp. pas_ domain_ sequence IS NOT NULL   ANDm. positionB ET WE EN start_ index AND end_ index ) mut ations  JO IN cell_ lines cl ON mut ations. id= cl. mut ation_ id -- assuming there isa mut ation_ id column in cell_ lines table W HERE cl. id= pro state_ cell_ line_ id  ORDER BY\n",
      "You are an exceptional computational biologist and genomics expert and know everything about drug discovery.. Please write the appropriate SQL query using these three tables. The tables can be understood as utils/database_description.json. Try to answer the following question. The SQL should be returned within ''' SQL query '''. \"Relationship between dependency scores of JAK1 in DepMapDB.\"\n",
      "Output is: <generator object Prediction.output_iterator at 0x177ade4d0>\n",
      "Output is: Based on the information provided in the database description JSON file,I assume we have three tables named` comp ounds `,` gen es `, and` depend ency_ sc ores `. The` depend ency_ sc ores` table likely hasa composite primary key consisting of` comp ound_ id` and`g ene_ id `. Here's the SQL query to find the dependency scores ofJ AK1 for all comp ounds in Dep Map DB:   ``` SQL  SELECTc. name AS compound_ name,d. score AS dependency_ score  FROM comp oundsc  JO IN dependency_ sc oresd ONc. id=d. comp ound_ id  JO IN genesg ONd.g ene_ id=g. id W HEREg. symbol='J AK1 ';  ```   This query selects the compound name and dependency score for all records where the associated gene symbol is'J AK1 '.\n"
     ]
    }
   ],
   "source": [
    "# LLM checks to write a SQL query\n",
    "\n",
    "import replicate\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import config\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "from config import config, reset_config\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# import logging\n",
    "\n",
    "# # Set the logging level for httpx to WARNING\n",
    "# logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "folder_path = 'files'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "reset_config()\n",
    "config.set_mode('dbs')\n",
    "\n",
    "INSTRUCTION = config.INSTRUCTION\n",
    "F_NAME = config.F_NAME\n",
    "\n",
    "def load_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "perturbations = load_file(config.perturbations)\n",
    "knowledgebase = load_file(config.knowledgebase)\n",
    "db_desc = load_file(config.db_layout)\n",
    "\n",
    "df = pd.read_excel(config.questions)\n",
    "df.to_excel(config.q_original, index=False)\n",
    "\n",
    "df['Question'] = df['Question'].str.strip()  # Removes leading/trailing whitespace\n",
    "\n",
    "# Check for duplicate questions\n",
    "duplicates = df.duplicated(subset=['Question'], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"Duplicates found. Removing duplicates.\")\n",
    "    df = df.drop_duplicates(subset=['Question'], keep='first')\n",
    "    df.to_excel(config.q_db, index=False)\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Question', 'Response'])\n",
    "\n",
    "models = {\n",
    "    # \"qwen-14b\": \"nomagick/qwen-14b-chat:f9e1ed25e2073f72ff9a3f46545d909b1078e674da543e791dec79218072ae70\",\n",
    "    # \"falcon-40b\": \"joehoover/falcon-40b-instruct:7d58d6bddc53c23fa451c403b2b5373b1e0fa094e4e0d1b98c3d02931aa07173\",\n",
    "    # \"yi-34b\": \"01-ai/yi-34b-chat:914692bbe8a8e2b91a4e44203e70d170c9c5ccc1359b283c84b0ec8d47819a46\",\n",
    "    \"mistral-7b\": \"mistralai/mistral-7b-instruct-v0.2:f5701ad84de5715051cb99d550539719f8a7fbcf65e0e62a3d1eb3f94720764e\",\n",
    "    # \"llama2-70b\": \"meta/llama-2-70b-chat\",\n",
    "    # \"openhermes2\": \"antoinelyset/openhermes-2.5-mistral-7b:d7ccd25700fb11c1787c25b580ac8d715d2b677202fe54b77f9b4a1eb7d73e2b\",\n",
    "    # \"mixtral-instruct\": \"mistralai/mixtral-8x7b-instruct-v0.1:2b56576fcfbe32fa0526897d8385dd3fb3d36ba6fd0dbe033c72886b81ade93e\",\n",
    "    # \"deepseek_33bq\": \"kcaverly/deepseek-coder-33b-instruct-gguf:ea964345066a8868e43aca432f314822660b72e29cab6b4b904b779014fe58fd\",\n",
    "    }\n",
    "\n",
    "prompt_for_qwen=\"\"\"<|im_start|>system\\n {INSTRUCTION}. Please write the appropriate SQL query using these three tables. The tables can be understood as {config.db_layout}. Try to answer the following question. The SQL should be returned within ''' SQL query '''. <|im_end|>\\n<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\\n\"\"\"\n",
    "prompt_for_hermes = \"\"\"[\n",
    "{{\n",
    "  \"role\": \"system\",\n",
    "  \"content\": \"{INSTRUCTION}. Please write the appropriate SQL query using these three tables. The tables can be understood as {config.db_layout}. Try to answer the following question. The SQL should be returned within ''' SQL query ''' \" \n",
    "}},\n",
    "{{\n",
    "  \"role\": \"user\",\n",
    "  \"content\": {question}\n",
    "}}\n",
    "]\"\"\"\n",
    "\n",
    "# Iterate through each model\n",
    "for model_key, model_value in models.items():\n",
    "    responses = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        qn = row['Question']\n",
    "        question = json.dumps(qn)\n",
    "\n",
    "        if model_key == \"yi-34b\":  # Yi model\n",
    "            prompt = prompt_for_qwen.format(INSTRUCTION=INSTRUCTION, question=question)\n",
    "        if model_key == \"qwen-14b\":  # Qwen model\n",
    "            prompt = prompt_for_qwen.format(INSTRUCTION=INSTRUCTION, question=question)\n",
    "        elif model_key == \"openhermes2\":  # Hermes model\n",
    "            prompt = prompt_for_hermes.format(INSTRUCTION=INSTRUCTION, question=question)\n",
    "        else:\n",
    "            prompt = f\"{INSTRUCTION}. Please write the appropriate SQL query using these three tables. The tables can be understood as {config.db_layout}. Try to answer the following question. The SQL should be returned within ''' SQL query '''. {question}\"\n",
    "\n",
    "        try:\n",
    "            print(prompt)\n",
    "            output = replicate.run(\n",
    "                model_value,\n",
    "                input={\n",
    "                  \"debug\": False,\n",
    "                #   \"top_k\": 50,\n",
    "                  \"top_p\": 0.9,\n",
    "                  \"prompt\": prompt,\n",
    "                  \"temperature\": 0.7,\n",
    "                  \"max_new_tokens\": 500,\n",
    "                  \"min_new_tokens\": -1\n",
    "                }\n",
    "            )\n",
    "            response = \"\"\n",
    "            response_parts = []  # Initialize an empty list to collect string representations\n",
    "            print(f\"Output is: {output}\")\n",
    "            for item in output:\n",
    "                item_str = str(item).strip()  # Convert item to string\n",
    "                response += item_str if len(item_str) == 1 else f\" {item_str}\"\n",
    "\n",
    "            response = response.strip()\n",
    "            print(f\"Output is: {response}\")\n",
    "            extracted_sql = extract_sql(response) # Get only the SQL query\n",
    "            print(f\"Output is: {extracted_sql}\")\n",
    "            valid = is_sql_valid(response) # Check if the SQL query is valid\n",
    "            response = {\n",
    "                \"response\": extracted_sql,\n",
    "                \"is_valid\": valid\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            response = f\"Error: {e}\"\n",
    "\n",
    "        new_row = pd.DataFrame({'Model': [model_key], 'Question': [qn], 'Response': [extracted_sql]})\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        if index % 20 == 0:  # Save every 10 questions, adjust as needed\n",
    "            results_df.to_excel(config.results_file_path, index=False, sheet_name='Sheet1')\n",
    "            \n",
    "results_df.to_excel(config.results_file_path, index=False, sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4 writes a SQL query\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "folder_path = 'files'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "INSTRUCTION = config['instructions']\n",
    "F_NAME = config[\"name\"]\n",
    "GPT_MODEL = config[\"GPT_MODEL\"]\n",
    "INPUT_CSV_PATH = 'files/questions_db.xlsx'\n",
    "OUTPUT_CSV_PATH = f'files/{F_NAME}_results_gpt4_db.xlsx'\n",
    "\n",
    "client = OpenAI()\n",
    "def show_json(obj):\n",
    "    print(json.loads(obj.model_dump_json()))\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=f\"{F_NAME} AI Evaluator via reading DB\",\n",
    "    instructions=INSTRUCTION,\n",
    "    model=GPT_MODEL,\n",
    ")\n",
    "show_json(assistant)\n",
    "\n",
    "# Utility functions\n",
    "def read_csv(file_path):\n",
    "    return pd.read_excel(file_path)\n",
    "\n",
    "def process_data_for_gpt(data):\n",
    "    prompts = []\n",
    "    for _, row in data.iterrows():\n",
    "        question = row['Question']\n",
    "        prompt = f\"Please write the appropriate SQL query using these three table schemas {all_schemas} to answer the following question. The SQL should be returned within ''' SQL query '''.:\\n\\n{question}\"\n",
    "        prompts.append(prompt)\n",
    "    return prompts\n",
    "\n",
    "def submit_message_and_create_run(assistant_id, prompt):\n",
    "    thread = client.beta.threads.create() # If you replace this globally it appends all answers to the one before.\n",
    "    client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=prompt)\n",
    "    return client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id), thread\n",
    "\n",
    "def wait_on_run_and_get_response(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        time.sleep(0.5)\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")\n",
    "    return [m.content[0].text.value for m in messages if m.role == 'assistant']\n",
    "\n",
    "def create_output_csv(data, responses, model_name, interim_csv_path):\n",
    "    new_rows = []\n",
    "    for question, response in zip(data['Question'], responses):\n",
    "        new_rows.append({'Model': model_name, 'Question': question, 'Response': response})\n",
    "    new_data = pd.DataFrame(new_rows)\n",
    "    new_data.to_excel(interim_csv_path, index=False)\n",
    "\n",
    "data = read_csv(INPUT_CSV_PATH)\n",
    "prompts = process_data_for_gpt(data)\n",
    "ASSISTANT_ID = assistant.id\n",
    "\n",
    "responses = []\n",
    "for prompt in prompts:\n",
    "    run, thread = submit_message_and_create_run(ASSISTANT_ID, prompt)\n",
    "    response = wait_on_run_and_get_response(run, thread)\n",
    "    if isinstance(response, list):\n",
    "        response = ' '.join(map(str, response))\n",
    "    response = response.replace(\"\\\\\\\\n\", \"\\\\n\")\n",
    "    response = response.strip()\n",
    "    extracted_sql = extract_sql(response) # Get only the SQL query\n",
    "    valid = is_sql_valid(response) # Check if the SQL query is valid\n",
    "    response = {\n",
    "        \"response\": extracted_sql,\n",
    "        \"is_valid\": valid\n",
    "    }\n",
    "    print(response)\n",
    "    responses.append(response)\n",
    "\n",
    "create_output_csv(data, responses, GPT_MODEL, OUTPUT_CSV_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
