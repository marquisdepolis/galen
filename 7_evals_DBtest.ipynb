{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccle_cn_gistic\n",
      "\n",
      "Table: ccle_cn_gistic in files/db/CCLEGisticCNDB.db\n",
      "MetaData()\n",
      "Schema:\n",
      "(0, 'Hugo_Symbol', 'TEXT', 0, None, 0)\n",
      "(1, 'CCLE_Name', 'TEXT', 0, None, 0)\n",
      "(2, 'gistic_cn', 'REAL', 0, None, 0)\n",
      "(3, 'DepMap_ID', 'TEXT', 0, None, 0)\n",
      "('A1BG', 'DMS53_LUNG', 0.0, 'ACH-000698')\n",
      "('A1BG', 'SW1116_LARGE_INTESTINE', 0.0, 'ACH-000489')\n",
      "('A1BG', 'NCIH1694_LUNG', 0.0, 'ACH-000431')\n",
      "('A1BG', 'P3HR1_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE', 0.0, 'ACH-000707')\n",
      "('A1BG', 'HUT78_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE', 0.0, 'ACH-000509')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>There are no different proteins associated with lymphoid tissue in the query results.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccle_mutation\n",
      "\n",
      "Table: ccle_mutation in files/db/CCLEMutDB.db\n",
      "MetaData()\n",
      "Schema:\n",
      "(0, 'Hugo_Symbol', 'TEXT', 0, None, 0)\n",
      "(1, 'Entrez_Gene_Id', 'INTEGER', 0, None, 0)\n",
      "(2, 'NCBI_Build', 'INTEGER', 0, None, 0)\n",
      "(3, 'Chromosome', 'TEXT', 0, None, 0)\n",
      "(4, 'Start_position', 'INTEGER', 0, None, 0)\n",
      "(5, 'End_position', 'INTEGER', 0, None, 0)\n",
      "(6, 'Strand', 'TEXT', 0, None, 0)\n",
      "(7, 'Variant_Classification', 'TEXT', 0, None, 0)\n",
      "(8, 'Variant_Type', 'TEXT', 0, None, 0)\n",
      "(9, 'Reference_Allele', 'TEXT', 0, None, 0)\n",
      "(10, 'Alternate_Allele', 'TEXT', 0, None, 0)\n",
      "(11, 'dbSNP_RS', 'TEXT', 0, None, 0)\n",
      "(12, 'dbSNP_Val_Status', 'TEXT', 0, None, 0)\n",
      "(13, 'Genome_Change', 'TEXT', 0, None, 0)\n",
      "(14, 'Annotation_Transcript', 'TEXT', 0, None, 0)\n",
      "(15, 'DepMap_ID', 'TEXT', 0, None, 0)\n",
      "(16, 'cDNA_Change', 'TEXT', 0, None, 0)\n",
      "(17, 'Codon_Change', 'TEXT', 0, None, 0)\n",
      "(18, 'Protein_Change', 'TEXT', 0, None, 0)\n",
      "(19, 'isDeleterious', 'TEXT', 0, None, 0)\n",
      "(20, 'isTCGAhotspot', 'TEXT', 0, None, 0)\n",
      "(21, 'TCGAhsCnt', 'REAL', 0, None, 0)\n",
      "(22, 'isCOSMIChotspot', 'TEXT', 0, None, 0)\n",
      "(23, 'COSMIChsCnt', 'REAL', 0, None, 0)\n",
      "(24, 'ExAC_AF', 'REAL', 0, None, 0)\n",
      "(25, 'Variant_annotation', 'TEXT', 0, None, 0)\n",
      "(26, 'CGA_WES_AC', 'TEXT', 0, None, 0)\n",
      "(27, 'HC_AC', 'TEXT', 0, None, 0)\n",
      "(28, 'RD_AC', 'TEXT', 0, None, 0)\n",
      "(29, 'RNAseq_AC', 'TEXT', 0, None, 0)\n",
      "(30, 'SangerWES_AC', 'TEXT', 0, None, 0)\n",
      "(31, 'WGS_AC', 'TEXT', 0, None, 0)\n",
      "('VPS13D', 55187, 37, '1', 12359347, 12359347, '+', 'Nonsense_Mutation', 'SNP', 'C', 'A', '', '', 'g.chr1:12359347C>A', 'ENST00000358136.3', 'ACH-000001', 'c.6122C>A', 'c.(6121-6123)tCa>tAa', 'p.S2041*', 'True', 'False', None, 'False', 0.0, None, 'damaging', '34:213', '', '', '', '34:221', '')\n",
      "('AADACL4', 343066, 37, '1', 12726308, 12726322, '+', 'In_Frame_Del', 'DEL', 'CTGGCGTGACGCCAT', '-', 'rs58218425|rs139261871|rs369427733|rs560787141', 'byFrequency', 'g.chr1:12726308_12726322delCTGGCGTGACGCCAT', 'ENST00000376221.1', 'ACH-000001', 'c.786_800delCTGGCGTGACGCCAT', 'c.(784-801)tcctggcgtgacgccatc>tcc', 'p.WRDAI263del', 'False', 'False', None, 'False', 3.0, None, 'other non-conserving', '57:141', '', '', '', '9:0', '28:32')\n",
      "('IFNLR1', 163702, 37, '1', 24484172, 24484172, '+', 'Silent', 'SNP', 'G', 'A', '', '', 'g.chr1:24484172G>A', 'ENST00000327535.1', 'ACH-000001', 'c.1011C>T', 'c.(1009-1011)ggC>ggT', 'p.G337G', 'False', 'False', None, 'False', 0.0, None, 'silent', '118:0', '', '', '10:0', '118:0', '18:0')\n",
      "('TMEM57', 55219, 37, '1', 25785018, 25785019, '+', 'Frame_Shift_Ins', 'INS', '-', 'A', '', '', 'g.chr1:25785018_25785019insA', 'ENST00000374343.4', 'ACH-000001', 'c.789_790insA', 'c.(790-792)aaafs', 'p.K264fs', 'True', 'False', 0.0, 'False', 0.0, None, 'damaging', '', '', '', '6:28', '', '')\n",
      "('ZSCAN20', 7579, 37, '1', 33954141, 33954141, '+', 'Missense_Mutation', 'SNP', 'T', 'G', '', '', 'g.chr1:33954141T>G', 'ENST00000361328.3', 'ACH-000001', 'c.494T>G', 'c.(493-495)gTg>gGg', 'p.V165G', 'False', 'False', None, 'False', 0.0, None, 'other non-conserving', '28:62', '', '', '', '27:61', '')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>There are no different proteins with lymphoid tissue.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccle_variants\n",
      "\n",
      "Table: ccle_variants in files/db/CCLEVarDB.db\n",
      "MetaData()\n",
      "Schema:\n",
      "(0, 'DepMap_ID', 'TEXT', 0, None, 0)\n",
      "(1, 'Chrom', 'TEXT', 0, None, 0)\n",
      "(2, 'Pos', 'INTEGER', 0, None, 0)\n",
      "(3, 'Ref', 'TEXT', 0, None, 0)\n",
      "(4, 'Alt', 'TEXT', 0, None, 0)\n",
      "(5, 'AF', 'REAL', 0, None, 0)\n",
      "(6, 'VariantType', 'TEXT', 0, None, 0)\n",
      "(7, 'VariantInfo', 'TEXT', 0, None, 0)\n",
      "(8, 'DNAChange', 'TEXT', 0, None, 0)\n",
      "(9, 'ProteinChange', 'TEXT', 0, None, 0)\n",
      "(10, 'gene_name', 'TEXT', 0, None, 0)\n",
      "(11, 'Transcript', 'TEXT', 0, None, 0)\n",
      "(12, 'CCLEDeleterious', 'TEXT', 0, None, 0)\n",
      "(13, 'CosmicHotspot', 'TEXT', 0, None, 0)\n",
      "(14, 'AssociatedWith', 'TEXT', 0, None, 0)\n",
      "(15, 'LoF', 'TEXT', 0, None, 0)\n",
      "(16, 'Driver', 'TEXT', 0, None, 0)\n",
      "(17, 'LikelyDriver', 'TEXT', 0, None, 0)\n",
      "(18, 'LikelyGoF', 'TEXT', 0, None, 0)\n",
      "(19, 'LikelyLoF', 'TEXT', 0, None, 0)\n",
      "(20, 'VariantAnnotation', 'TEXT', 0, None, 0)\n",
      "(21, 'copy_number', 'TEXT', 0, None, 0)\n",
      "('ACH-000839', 'chr1', 1242864, 'GC', 'CT', 0.31, 'DNP', 'MISSENSE', 'c.780_781GC>AG', 'p.L261V', 'C1QTNF12', 'ENST00000330388.2', 'False', 'False', '', 'False', 'False', 'False', 'False', 'False', 'Other', 'Diploid')\n",
      "('ACH-000839', 'chr1', 10647969, 'A', 'G', 0.4, 'SNP', 'MISSENSE', 'c.3329T>C', 'p.V1110A', 'CASZ1', 'ENST00000377022.8', 'False', 'False', '', 'False', 'False', 'False', 'False', 'False', 'Other', 'Diploid')\n",
      "('ACH-000839', 'chr1', 10648097, 'T', 'G', 0.349, 'SNP', 'SILENT', 'c.3201A>C', 'p.T1067T', 'CASZ1', 'ENST00000377022.8', 'False', 'False', '', 'False', 'False', 'False', 'False', 'False', 'Silent', 'Diploid')\n",
      "('ACH-000839', 'chr1', 13198424, 'G', 'A', 0.833, 'SNP', 'MISSENSE', 'c.770C>T', 'p.T257I', 'PRAMEF13', 'ENST00000625019.3', 'False', 'False', '', 'False', 'False', 'False', 'False', 'False', 'Other', 'Diploid')\n",
      "('ACH-000839', 'chr1', 13225068, 'A', 'G', 0.396, 'SNP', 'MISSENSE', 'c.653T>C', 'p.L218P', 'PRAMEF18', 'ENST00000624297.2', 'False', 'False', '', 'False', 'False', 'False', 'False', 'False', 'Other', 'Diploid')\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>There are no different proteins associated with lymphoid tissue.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from llama_index import SQLDatabase, ServiceContext\n",
    "import sqlite3\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.indices.struct_store.sql_query import (\n",
    "    SQLTableRetrieverQueryEngine,\n",
    ")\n",
    "from llama_index.objects import (\n",
    "    SQLTableNodeMapping,\n",
    "    ObjectIndex,\n",
    "    SQLTableSchema,\n",
    ")\n",
    "from llama_index import VectorStoreIndex\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    ")\n",
    "import os\n",
    "\n",
    "db_dir = \"files/db\"\n",
    "db_files = [os.path.join(db_dir, file) for file in os.listdir(db_dir) if file.endswith('.db')]\n",
    "\n",
    "for db_file in db_files:\n",
    "    engine = create_engine('sqlite:///' + db_file)\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get all tables\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "    tables = cursor.fetchall()\n",
    "    for table in tables:\n",
    "        print(table[0])\n",
    "\n",
    "    table_name = table[0]\n",
    "    print(f\"\\nTable: {table_name} in {db_file}\")\n",
    "    metadata_obj = MetaData()\n",
    "    print(metadata_obj)\n",
    "    # Get table schema\n",
    "    print(\"Schema:\")\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    schema = cursor.fetchall()\n",
    "    for column in schema:\n",
    "        print(column)\n",
    "\n",
    "    # Get the first five rows\n",
    "    # print(\"\\nFirst 5 rows:\")\n",
    "    cursor.execute(f\"SELECT * FROM {table_name} LIMIT 5;\")\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "\n",
    "    llm = OpenAI(temperature=0.1, model=\"gpt-3.5-turbo\")\n",
    "    service_context = ServiceContext.from_defaults(llm=llm)\n",
    "    sql_database = SQLDatabase(engine)\n",
    "    # set Logging to DEBUG for more detailed outputs\n",
    "    table_node_mapping = SQLTableNodeMapping(sql_database)\n",
    "    table_schema_objs = [\n",
    "        (SQLTableSchema(table_name=str(table_name)))\n",
    "    ]  # add a SQLTableSchema for each table\n",
    "\n",
    "    obj_index = ObjectIndex.from_objects(\n",
    "        table_schema_objs,\n",
    "        table_node_mapping,\n",
    "        VectorStoreIndex,\n",
    "    )\n",
    "    query_engine = SQLTableRetrieverQueryEngine(\n",
    "        sql_database, obj_index.as_retriever(similarity_top_k=3)\n",
    "    )\n",
    "    response = query_engine.query(\"How many different proteins with lymphoid tissue?\")\n",
    "    display(Markdown(f\"<b>{response}</b>\"))\n",
    "    # Close the cursor and connection\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for ccle_cn_gistic in files/db/CCLEGisticCNDB.db:\n",
      "ccle_cn_gistic.Hugo_Symbol\n",
      "ccle_cn_gistic.CCLE_Name\n",
      "ccle_cn_gistic.gistic_cn\n",
      "ccle_cn_gistic.DepMap_ID\n",
      "\n",
      "Schema for ccle_mutation in files/db/CCLEMutDB.db:\n",
      "ccle_mutation.Hugo_Symbol\n",
      "ccle_mutation.Entrez_Gene_Id\n",
      "ccle_mutation.NCBI_Build\n",
      "ccle_mutation.Chromosome\n",
      "ccle_mutation.Start_position\n",
      "ccle_mutation.End_position\n",
      "ccle_mutation.Strand\n",
      "ccle_mutation.Variant_Classification\n",
      "ccle_mutation.Variant_Type\n",
      "ccle_mutation.Reference_Allele\n",
      "ccle_mutation.Alternate_Allele\n",
      "ccle_mutation.dbSNP_RS\n",
      "ccle_mutation.dbSNP_Val_Status\n",
      "ccle_mutation.Genome_Change\n",
      "ccle_mutation.Annotation_Transcript\n",
      "ccle_mutation.DepMap_ID\n",
      "ccle_mutation.cDNA_Change\n",
      "ccle_mutation.Codon_Change\n",
      "ccle_mutation.Protein_Change\n",
      "ccle_mutation.isDeleterious\n",
      "ccle_mutation.isTCGAhotspot\n",
      "ccle_mutation.TCGAhsCnt\n",
      "ccle_mutation.isCOSMIChotspot\n",
      "ccle_mutation.COSMIChsCnt\n",
      "ccle_mutation.ExAC_AF\n",
      "ccle_mutation.Variant_annotation\n",
      "ccle_mutation.CGA_WES_AC\n",
      "ccle_mutation.HC_AC\n",
      "ccle_mutation.RD_AC\n",
      "ccle_mutation.RNAseq_AC\n",
      "ccle_mutation.SangerWES_AC\n",
      "ccle_mutation.WGS_AC\n",
      "\n",
      "Schema for ccle_variants in files/db/CCLEVarDB.db:\n",
      "ccle_variants.DepMap_ID\n",
      "ccle_variants.Chrom\n",
      "ccle_variants.Pos\n",
      "ccle_variants.Ref\n",
      "ccle_variants.Alt\n",
      "ccle_variants.AF\n",
      "ccle_variants.VariantType\n",
      "ccle_variants.VariantInfo\n",
      "ccle_variants.DNAChange\n",
      "ccle_variants.ProteinChange\n",
      "ccle_variants.gene_name\n",
      "ccle_variants.Transcript\n",
      "ccle_variants.CCLEDeleterious\n",
      "ccle_variants.CosmicHotspot\n",
      "ccle_variants.AssociatedWith\n",
      "ccle_variants.LoF\n",
      "ccle_variants.Driver\n",
      "ccle_variants.LikelyDriver\n",
      "ccle_variants.LikelyGoF\n",
      "ccle_variants.LikelyLoF\n",
      "ccle_variants.VariantAnnotation\n",
      "ccle_variants.copy_number\n"
     ]
    }
   ],
   "source": [
    "# Create combined schema of tables\n",
    "\n",
    "import sqlite3\n",
    "import json\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, String\n",
    "import re\n",
    "def combine_schemas(db_files):\n",
    "    combined_schema = {}\n",
    "\n",
    "    for db_file in db_files:\n",
    "        engine = create_engine('sqlite:///' + db_file)\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Get all tables\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cursor.fetchall()\n",
    "\n",
    "        for table in tables:\n",
    "            table_name = table[0]\n",
    "            metadata_obj = MetaData()\n",
    "            \n",
    "            # Get table schema\n",
    "            cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "            schema = cursor.fetchall()\n",
    "\n",
    "            # Create a Table object to store schema info\n",
    "            table_obj = Table(table_name, metadata_obj)\n",
    "\n",
    "            for column in schema:\n",
    "                col_name, col_type = column[1], column[2]\n",
    "                # Add column to the table object\n",
    "                table_obj.append_column(Column(col_name, String))\n",
    "\n",
    "            # Serialize table schema\n",
    "            schema_info = [{\"column_name\": col.name, \"data_type\": str(col.type)} for col in table_obj.columns]\n",
    "            combined_schema[f\"{table_name} in {db_file}\"] = schema_info\n",
    "\n",
    "        conn.close()\n",
    "\n",
    "    return combined_schema\n",
    "\n",
    "def save_schema_to_json(combined_schema, filename=\"combined_schema.json\"):\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(combined_schema, file, indent=4)\n",
    "\n",
    "# Paths to your database files\n",
    "db_files = [\"files/db/CCLEGisticCNDB.db\" , 'files/db/CCLEMutDB.db', 'files/db/CCLEVarDB.db']\n",
    "all_schemas = combine_schemas(db_files)\n",
    "save_schema_to_json(all_schemas)\n",
    "\n",
    "# Now the schema is saved in 'combined_schema.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A check\n",
    "import re \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def extract_sql(llm_response: str) -> str:\n",
    "    # If the llm_response contains a markdown code block, with or without the sql tag, extract the sql from it\n",
    "    sql = re.search(r\"```sql\\n(.*)```\", llm_response, re.DOTALL)\n",
    "    if sql:\n",
    "        log(f\"Output from LLM: {llm_response} \\nExtracted SQL: {sql.group(1)}\")\n",
    "        return sql.group(1)\n",
    "\n",
    "    sql = re.search(r\"```(.*)```\", llm_response, re.DOTALL)\n",
    "    if sql:\n",
    "        log(f\"Output from LLM: {llm_response} \\nExtracted SQL: {sql.group(1)}\")\n",
    "        return sql.group(1)\n",
    "\n",
    "    return llm_response\n",
    "\n",
    "def is_sql_valid(sql: str) -> bool:\n",
    "    # This is a check to see the SQL is valid and should be run\n",
    "    # This simple function just checks if the SQL contains a SELECT statement\n",
    "\n",
    "    if \"SELECT\" in sql.upper():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM checks to write a SQL query\n",
    "\n",
    "import replicate\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "folder_path = 'files'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "INSTRUCTION = config['instructions']\n",
    "F_NAME = config[\"name\"]\n",
    "\n",
    "# # Load the file\n",
    "df = pd.read_excel('files/questions_db.xlsx')\n",
    "# Save the original DataFrame\n",
    "df.to_excel('files/questions_original_db.xlsx', index=False)\n",
    "\n",
    "# Trim whitespace and newline characters\n",
    "df['Question'] = df['Question'].str.strip()  # Removes leading/trailing whitespace\n",
    "\n",
    "# Check for duplicate questions\n",
    "duplicates = df.duplicated(subset=['Question'], keep=False)\n",
    "if duplicates.any():\n",
    "    print(\"Duplicates found. Removing duplicates.\")\n",
    "\n",
    "    # Remove duplicates, keeping the first occurrence\n",
    "    df = df.drop_duplicates(subset=['Question'], keep='first')\n",
    "\n",
    "    # Save the modified DataFrame, overwriting the original 'questions.xlsx'\n",
    "    df.to_excel('files/questions_db.xlsx', index=False)\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n",
    "\n",
    "# DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Question', 'Response'])\n",
    "\n",
    "models = {\n",
    "    \"qwen-14b\": \"nomagick/qwen-14b-chat:f9e1ed25e2073f72ff9a3f46545d909b1078e674da543e791dec79218072ae70\",\n",
    "    \"falcon-40b\": \"joehoover/falcon-40b-instruct:7d58d6bddc53c23fa451c403b2b5373b1e0fa094e4e0d1b98c3d02931aa07173\",\n",
    "    \"yi-34b\": \"01-ai/yi-34b-chat:914692bbe8a8e2b91a4e44203e70d170c9c5ccc1359b283c84b0ec8d47819a46\",\n",
    "    \"mistral-7b\": \"mistralai/mistral-7b-instruct-v0.2:f5701ad84de5715051cb99d550539719f8a7fbcf65e0e62a3d1eb3f94720764e\",\n",
    "    \"llama2-70b\": \"meta/llama-2-70b-chat\",\n",
    "    \"openhermes2\": \"antoinelyset/openhermes-2.5-mistral-7b:d7ccd25700fb11c1787c25b580ac8d715d2b677202fe54b77f9b4a1eb7d73e2b\",\n",
    "    \"mixtral-instruct\": \"mistralai/mixtral-8x7b-instruct-v0.1:2b56576fcfbe32fa0526897d8385dd3fb3d36ba6fd0dbe033c72886b81ade93e\",\n",
    "    \"deepseek_33bq\": \"kcaverly/deepseek-coder-33b-instruct-gguf:ea964345066a8868e43aca432f314822660b72e29cab6b4b904b779014fe58fd\",\n",
    "    }\n",
    "\n",
    "prompt_for_qwen=\"\"\"<|im_start|>system\\n {INSTRUCTION}. Please write the appropriate SQL query using these three table schemas {all_schemas} to answer the following question. The SQL should be returned within ''' SQL query '''. <|im_end|>\\n<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\\n\"\"\"\n",
    "prompt_for_hermes = \"\"\"[\n",
    "{{\n",
    "  \"role\": \"system\",\n",
    "  \"content\": \"{INSTRUCTION}. Please write the appropriate SQL query using these three table schemas {all_schemas} to answer the following question. The SQL should be returned within ''' SQL query ''' \" \n",
    "}},\n",
    "{{\n",
    "  \"role\": \"user\",\n",
    "  \"content\": {question}\n",
    "}}\n",
    "]\"\"\"\n",
    "\n",
    "# Iterate through each model\n",
    "for model_key, model_value in models.items():\n",
    "    responses = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        qn = row['Question']\n",
    "        question = json.dumps(qn)\n",
    "\n",
    "        if model_key == \"yi-34b\":  # Yi model\n",
    "            prompt = prompt_for_qwen.format(INSTRUCTION=INSTRUCTION, question=question)\n",
    "        if model_key == \"qwen-14b\":  # Qwen model\n",
    "            prompt = prompt_for_qwen.format(INSTRUCTION=INSTRUCTION, question=question)\n",
    "        elif model_key == \"openhermes2\":  # Hermes model\n",
    "            prompt = prompt_for_hermes.format(INSTRUCTION=INSTRUCTION, question=question)\n",
    "        else:\n",
    "            plain_text_question = json.loads(question)\n",
    "            prompt = f\"{INSTRUCTION}. Please write the appropriate SQL query using these three table schemas {all_schemas} to answer the following question. The SQL should be returned within ''' SQL query '''. {plain_text_question}\"\n",
    "\n",
    "        try:\n",
    "            print(prompt)\n",
    "            output = replicate.run(\n",
    "                model_value,\n",
    "                input={\n",
    "                  \"debug\": False,\n",
    "                #   \"top_k\": 50,\n",
    "                  \"top_p\": 0.9,\n",
    "                  \"prompt\": prompt,\n",
    "                  \"temperature\": 0.7,\n",
    "                  \"max_new_tokens\": 500,\n",
    "                  \"min_new_tokens\": -1\n",
    "                }\n",
    "            )\n",
    "            response = \"\"\n",
    "            response_parts = []  # Initialize an empty list to collect string representations\n",
    "\n",
    "            for item in output:\n",
    "                item_str = str(item)  # Convert item to string\n",
    "                response += item_str if len(item_str) == 1 else f\" {item_str}\"\n",
    "                \n",
    "            response = response.strip()\n",
    "            extracted_sql = extract_sql(response) # Get only the SQL query\n",
    "            valid = is_sql_valid(response) # Check if the SQL query is valid\n",
    "            response = {\n",
    "                \"response\": extracted_sql,\n",
    "                \"is_valid\": valid\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            response = f\"Error: {e}\"\n",
    "\n",
    "        new_row = pd.DataFrame({'Model': [model_key], 'Question': [qn], 'Response': [response]})\n",
    "        results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        if index % 20 == 0:  # Save every 10 questions, adjust as needed\n",
    "            results_df.to_excel(f'files/{F_NAME}_results_grouped_by_model_db.xlsx', index=False, sheet_name='Sheet1')\n",
    "            \n",
    "results_df.to_excel(f'files/{F_NAME}_results_grouped_by_model_db.xlsx', index=False, sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4 writes a SQL query\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "folder_path = 'files'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "INSTRUCTION = config['instructions']\n",
    "F_NAME = config[\"name\"]\n",
    "GPT_MODEL = config[\"GPT_MODEL\"]\n",
    "INPUT_CSV_PATH = 'files/questions_db.xlsx'\n",
    "OUTPUT_CSV_PATH = f'files/{F_NAME}_results_gpt4_db.xlsx'\n",
    "\n",
    "client = OpenAI()\n",
    "def show_json(obj):\n",
    "    print(json.loads(obj.model_dump_json()))\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=f\"{F_NAME} AI Evaluator via reading DB\",\n",
    "    instructions=INSTRUCTION,\n",
    "    model=GPT_MODEL,\n",
    ")\n",
    "show_json(assistant)\n",
    "\n",
    "# Utility functions\n",
    "def read_csv(file_path):\n",
    "    return pd.read_excel(file_path)\n",
    "\n",
    "def process_data_for_gpt(data):\n",
    "    prompts = []\n",
    "    for _, row in data.iterrows():\n",
    "        question = row['Question']\n",
    "        prompt = f\"Please write the appropriate SQL query using these three table schemas {all_schemas} to answer the following question. The SQL should be returned within ''' SQL query '''.:\\n\\n{question}\"\n",
    "        prompts.append(prompt)\n",
    "    return prompts\n",
    "\n",
    "def submit_message_and_create_run(assistant_id, prompt):\n",
    "    thread = client.beta.threads.create() # If you replace this globally it appends all answers to the one before.\n",
    "    client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=prompt)\n",
    "    return client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant_id), thread\n",
    "\n",
    "def wait_on_run_and_get_response(run, thread):\n",
    "    while run.status == \"queued\" or run.status == \"in_progress\":\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        time.sleep(0.5)\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")\n",
    "    return [m.content[0].text.value for m in messages if m.role == 'assistant']\n",
    "\n",
    "def create_output_csv(data, responses, model_name, interim_csv_path):\n",
    "    new_rows = []\n",
    "    for question, response in zip(data['Question'], responses):\n",
    "        new_rows.append({'Model': model_name, 'Question': question, 'Response': response})\n",
    "    new_data = pd.DataFrame(new_rows)\n",
    "    new_data.to_excel(interim_csv_path, index=False)\n",
    "\n",
    "data = read_csv(INPUT_CSV_PATH)\n",
    "prompts = process_data_for_gpt(data)\n",
    "ASSISTANT_ID = assistant.id\n",
    "\n",
    "responses = []\n",
    "for prompt in prompts:\n",
    "    run, thread = submit_message_and_create_run(ASSISTANT_ID, prompt)\n",
    "    response = wait_on_run_and_get_response(run, thread)\n",
    "    if isinstance(response, list):\n",
    "        response = ' '.join(map(str, response))\n",
    "    response = response.replace(\"\\\\\\\\n\", \"\\\\n\")\n",
    "    response = response.strip()\n",
    "    extracted_sql = extract_sql(response) # Get only the SQL query\n",
    "    valid = is_sql_valid(response) # Check if the SQL query is valid\n",
    "    response = {\n",
    "        \"response\": extracted_sql,\n",
    "        \"is_valid\": valid\n",
    "    }\n",
    "    print(response)\n",
    "    responses.append(response)\n",
    "\n",
    "create_output_csv(data, responses, GPT_MODEL, OUTPUT_CSV_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
